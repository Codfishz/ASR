{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17153,"status":"ok","timestamp":1745210089708,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"APC17Tt6f5Bh","outputId":"404ab286-2339-45b6-b560-c239c95571c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"n5odPXUk4iso"},"source":["# Dataloader"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10078,"status":"ok","timestamp":1745210099784,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"34iJrhoU2IuR"},"outputs":[],"source":["import os\n","from PIL import Image, UnidentifiedImageError\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import LabelEncoder\n","from torchvision import transforms\n","from torchvision.models import resnet18, ResNet18_Weights\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2622,"status":"ok","timestamp":1745210102409,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"x4dkyvngVk6T","outputId":"132496d9-d746-4356-d6d6-795b86aea1c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ASR'...\n","warning: redirecting to https://github.com/Codfishz/ASR.git/\n","remote: Enumerating objects: 107, done.\u001b[K\n","remote: Counting objects: 100% (107/107), done.\u001b[K\n","remote: Compressing objects: 100% (79/79), done.\u001b[K\n","remote: Total 107 (delta 55), reused 75 (delta 27), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (107/107), 12.29 MiB | 16.85 MiB/s, done.\n","Resolving deltas: 100% (55/55), done.\n"]}],"source":["# Settings -\u003e Developer Settings -\u003e Personal Access Tokens -\u003e Token (classic)\n","os.environ['GITHUB_TOKEN'] = \"\"\n","\n","GITHUB_USERNAME = \"Codfishz\"\n","REPO_NAME       = \"ASR\"\n","TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n","repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n","!git clone {repo_url}"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":603,"status":"ok","timestamp":1745210103020,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"oyCemzBtVk6T","outputId":"1bd6ca5a-ad46-438f-9ec0-268d62267a52"},"outputs":[{"name":"stdout","output_type":"stream","text":["warning: redirecting to https://github.com/Codfishz/ASR.git/\n","Already up to date.\n"]}],"source":["!cd {REPO_NAME} \u0026\u0026 git pull"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1745210103032,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"OvFAb4GKVk6U"},"outputs":[],"source":["os.chdir('ASR/Script')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113933,"status":"ok","timestamp":1745210216967,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"c8yE4LJAVk6U","outputId":"f65ab9e3-8136-4d4b-c49b-7332f9da1298"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kaggle==1.7.4.2\n","  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n","Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n","\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/173.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.7.4.2\n","    Uninstalling kaggle-1.7.4.2:\n","      Successfully uninstalled kaggle-1.7.4.2\n","Successfully installed kaggle-1.7.4.2\n","Dataset URL: https://www.kaggle.com/datasets/nirmalsankalana/crop-pest-and-disease-detection\n","License(s): CC0-1.0\n","‚úÖ Total images found in dataset: 25220\n","Images before filter: 25220\n"]},{"name":"stderr","output_type":"stream","text":["Saving train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20176/20176 [00:33\u003c00:00, 598.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","train split summary:\n","  Total images: 20093\n","\n"]},{"name":"stderr","output_type":"stream","text":["Saving val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2522/2522 [00:04\u003c00:00, 590.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","val split summary:\n","  Total images: 2514\n","\n"]},{"name":"stderr","output_type":"stream","text":["Saving test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2522/2522 [00:04\u003c00:00, 595.15it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","test split summary:\n","  Total images: 2519\n","\n","  Images after filter : 25126\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%run \"Datapreparation_YOLO.ipynb\""]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33297,"status":"ok","timestamp":1745210250269,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"G-a7Vh0gocUZ","outputId":"4282311e-ba12-4e77-a436-16eb50c45694"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing 'Cashew anthracnose': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1729/1729 [00:02\u003c00:00, 678.85it/s]\n","Processing 'Cashew gumosis': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 392/392 [00:00\u003c00:00, 657.75it/s]\n","Processing 'Cashew healthy': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1368/1368 [00:01\u003c00:00, 694.18it/s]\n","Processing 'Cashew leaf miner': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1378/1378 [00:01\u003c00:00, 746.82it/s]\n","Processing 'Cashew red rust': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1682/1682 [00:02\u003c00:00, 651.14it/s]\n","Processing 'Cassava bacterial blight': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2614/2614 [00:03\u003c00:00, 788.47it/s]\n","Processing 'Cassava brown spot': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1481/1481 [00:01\u003c00:00, 773.00it/s]\n","Processing 'Cassava green mite': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1015/1015 [00:01\u003c00:00, 765.96it/s]\n","Processing 'Cassava healthy': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1193/1193 [00:01\u003c00:00, 793.26it/s]\n","Processing 'Cassava mosaic': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1205/1205 [00:01\u003c00:00, 797.47it/s]\n","Processing 'Maize fall armyworm': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 285/285 [00:00\u003c00:00, 814.72it/s]\n","Processing 'Maize grasshoper': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 673/673 [00:00\u003c00:00, 818.58it/s]\n","Processing 'Maize healthy': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 208/208 [00:00\u003c00:00, 839.06it/s]\n","Processing 'Maize leaf beetle': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 948/948 [00:00\u003c00:00, 958.11it/s]\n","Processing 'Maize leaf blight': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1006/1006 [00:01\u003c00:00, 743.95it/s]\n","Processing 'Maize leaf spot': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1259/1259 [00:01\u003c00:00, 757.57it/s]\n","Processing 'Maize streak virus': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 979/979 [00:01\u003c00:00, 731.95it/s]\n","Processing 'Tomato healthy': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 470/470 [00:00\u003c00:00, 808.36it/s]\n","Processing 'Tomato leaf blight': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1301/1301 [00:01\u003c00:00, 778.62it/s]\n","Processing 'Tomato leaf curl': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 518/518 [00:00\u003c00:00, 812.76it/s]\n","Processing 'Tomato septoria leaf spot': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2743/2743 [00:03\u003c00:00, 797.00it/s]\n","Processing 'Tomato verticulium wilt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 773/773 [00:00\u003c00:00, 799.15it/s]\n"]}],"source":["# Categories\n","categories = sorted([d for d in os.listdir(original_base) if os.path.isdir(os.path.join(original_base, d))])\n","\n","# Set image path and labels\n","image_paths = []\n","image_labels = []\n","\n","base_path = \"/content/data\"\n","\n","for category in categories:\n","    category_dir = os.path.join(base_path, category)\n","    filenames = [f for f in os.listdir(category_dir) if f.endswith(\".jpg\")]\n","    for filename in tqdm(filenames, desc=f\"Processing '{category}'\"):\n","      image_path = os.path.join(category_dir, filename)\n","      try:\n","          img = Image.open(image_path)\n","          img = img.convert(\"RGB\")\n","          img.load()  # load image each time to remove the damaged image thoroughly\n","          image_paths.append(image_path)\n","          image_labels.append(category)\n","      except (UnidentifiedImageError, OSError):\n","          continue\n","\n","# Label encoder\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(image_labels)\n","\n","# Dataset\n","class CropDiseaseDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","        label = self.labels[idx]\n","        return image, label\n","\n","# Augmentation\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)), # To fit the pretrain model (ËØ¥ÊòØresnetÁöÑÂÆòÊñπÊé®ËçêËæìÂÖ•Â§ßÂ∞è)\n","    # transforms.RandomRotation(20),\n","    # transforms.ColorJitter(brightness=0.1, contrast=0.1),\n","    # transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # To fit the pretrain model (Ê≤°ÊúâÂæàÊáÇÂïäÔºåÂä†‰∏ä‰πãÂêéÂõæÁâáÁæ§È≠î‰π±Ëàû)\n","])\n","\n","\n","# Make Dataset and DataLoader\n","dataset = CropDiseaseDataset(image_paths, encoded_labels, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=0, pin_memory=True)\n","\n","# Visualization\n","# plt.figure(figsize=(10, 10))\n","# for images, labels in dataloader:\n","#     for i in range(9):\n","#         img = images[i].permute(1, 2, 0).numpy()\n","#         plt.subplot(3, 3, i+1)\n","#         plt.imshow(img)\n","#         plt.axis('off')\n","#     break\n","# plt.show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1745210250372,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"eATpJjs4nQ_Y","outputId":"d9e732df-787a-4010-dcd0-4498a2d2d878"},"outputs":[{"name":"stdout","output_type":"stream","text":["25126\n"]}],"source":["print(len(dataset))"]},{"cell_type":"markdown","metadata":{"id":"VG8dsAAI4bQ7"},"source":["# Feature extraction (ResNet18)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99077,"status":"ok","timestamp":1745210349450,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"Q4TBZQvu10LH","outputId":"23d7e8f8-46cb-410c-ab1c-020ff55187bd"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00\u003c00:00, 230MB/s]\n","Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:38\u003c00:00,  1.00it/s]\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pretrained ResNet\n","weights = ResNet18_Weights.DEFAULT\n","resnet18 = resnet18(weights=weights)\n","\n","# Remove the final fully connected layer\n","feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n","feature_extractor.to(device)\n","feature_extractor.eval()\n","\n","# Extract features\n","\n","def extract_features(dataloader, model, device):\n","    all_features = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(dataloader, desc=\"Extracting features\"):\n","            images = images.to(device)\n","            features = model(images)                  # shape: [B, 512, 1, 1]\n","            features = features.view(features.size(0), -1)  # flatten to [B, 512]\n","            all_features.append(features.cpu())\n","            all_labels.append(labels)\n","\n","    return torch.cat(all_features), torch.cat(all_labels)\n","\n","features, labels = extract_features(dataloader, feature_extractor, device)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1745210349465,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"s3Lolcnj4vos","outputId":"ed0b4562-278f-4deb-f75c-2e645da5b8f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Features shape: torch.Size([25126, 512])\n","Labels shape: torch.Size([25126])\n"]}],"source":["# Results\n","print(\"Features shape:\", features.shape)  # [N, 512]\n","print(\"Labels shape:\", labels.shape)      # [N]"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1745210349489,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"l_C56__M4v36"},"outputs":[],"source":["def select_density_samples_from_features(features, k=10):\n","    \"\"\"\n","    Select the top-k samples based on density computed from pre-extracted features.\n","\n","    Parameters:\n","        features: A NumPy array of shape (N, D), where N is the number of images\n","                  (e.g. 24453) and D is the feature dimension (e.g. 512).\n","        k: The number of samples to select.\n","\n","    Returns:\n","        selected_indices: The indices of the selected samples (top-k with highest density).\n","        density_scores: A NumPy array of density scores for all samples.\n","    \"\"\"\n","    # Normalize the feature vectors to unit length (to use cosine similarity)\n","    norms = np.linalg.norm(features, axis=1, keepdims=True) + 1e-8  # avoid division by zero\n","    norm_features = features / norms\n","\n","    # Compute the pairwise cosine similarity matrix.\n","    # Note: Similarity between feature i and j is the dot product of normalized features.\n","    similarity_matrix = np.dot(norm_features, norm_features.T)\n","\n","    # Remove self-similarity by setting the diagonal elements to 0.\n","    np.fill_diagonal(similarity_matrix, 0)\n","\n","    # Compute density score for each image: here we take the average similarity\n","    density_scores = similarity_matrix.mean(axis=1)\n","\n","    # Select the indices of the top-k samples with the highest density scores.\n","    selected_indices = np.argsort(density_scores)[-k:]\n","\n","    return selected_indices, density_scores\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68955,"status":"ok","timestamp":1745210418446,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"6t84cNrOVk6X","outputId":"8ab3b069-1741-4a4b-acc7-11ab9003b322"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Setup complete ‚úÖ (12 CPUs, 53.0 GB RAM, 43.7/235.7 GB disk)\n"]}],"source":["!pip install ultralytics\n","!pip install torchinfo\n","\n","import ultralytics\n","ultralytics.checks()\n"]},{"cell_type":"markdown","metadata":{"id":"IBtqqZhMVk6X"},"source":["# Functions"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1745210418488,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"LSbDNPPaVk6X"},"outputs":[],"source":["def setup_active_dataset():\n","\n","    orig_train_dir = os.path.join(ORIGINAL_DATASET_DIR, TRAIN_SUBDIR)\n","    active_train_dir = os.path.join(ACTIVE_DATASET_DIR, TRAIN_SUBDIR)\n","    os.makedirs(active_train_dir, exist_ok=True)\n","\n","    for cls in os.listdir(orig_train_dir):\n","        cls_path = os.path.join(orig_train_dir, cls)\n","        if os.path.isdir(cls_path):\n","            os.makedirs(os.path.join(active_train_dir, cls), exist_ok=True)\n","    print(f\"Complete creating train_dir {active_train_dir}\")\n","\n","    orig_val_dir = os.path.join(ORIGINAL_DATASET_DIR, VAL_SUBDIR)\n","    active_val_dir = os.path.join(ACTIVE_DATASET_DIR, VAL_SUBDIR)\n","    if os.path.exists(orig_val_dir):\n","        if os.path.exists(active_val_dir):\n","            shutil.rmtree(active_val_dir)\n","        shutil.copytree(orig_val_dir, active_val_dir)\n","\n","    orig_test_dir = os.path.join(ORIGINAL_DATASET_DIR, TEST_SUBDIR)\n","    active_test_dir = os.path.join(ACTIVE_DATASET_DIR, TEST_SUBDIR)\n","    if os.path.exists(orig_test_dir):\n","        if os.path.exists(active_test_dir):\n","            shutil.rmtree(active_test_dir)\n","        shutil.copytree(orig_test_dir, active_test_dir)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1745210418498,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"LWsTUCDFVk6Y"},"outputs":[],"source":["def get_all_samples():\n","\n","    samples = []\n","    orig_train_dir = os.path.join(ORIGINAL_DATASET_DIR, TRAIN_SUBDIR)\n","    for cls in os.listdir(orig_train_dir):\n","        cls_path = os.path.join(orig_train_dir, cls)\n","        if os.path.isdir(cls_path):\n","            image_files = [f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]\n","            for f in image_files:\n","                samples.append((cls, f))\n","    return samples"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1745210418523,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"xEMoCCC7Vk6Y"},"outputs":[],"source":["import shutil\n","def copy_samples(sample_list):\n","\n","    for cls, file_name in sample_list:\n","        src_path = os.path.join(ORIGINAL_DATASET_DIR, TRAIN_SUBDIR, cls, file_name)\n","        dst_path = os.path.join(ACTIVE_DATASET_DIR, TRAIN_SUBDIR, cls, file_name)\n","        if not os.path.exists(dst_path):\n","            shutil.copy(src_path, dst_path)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745210418527,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"Z3JIgEElVk6Y"},"outputs":[],"source":["import random\n","def stratified_sample(all_samples, n_initial):\n","\n","    samples_by_class = {}\n","    for cls, filename in all_samples:\n","        samples_by_class.setdefault(cls, []).append((cls, filename))\n","\n","    stratified = []\n","    for cls, samples in samples_by_class.items():\n","        stratified.append(random.choice(samples))\n","    remaining_count = n_initial - len(stratified)\n","    if remaining_count \u003e 0:\n","        remaining_samples = list(set(all_samples) - set(stratified))\n","        additional_samples = random.sample(remaining_samples, remaining_count)\n","        stratified.extend(additional_samples)\n","\n","    return stratified\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5M6GPmEfVk6Y"},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1745210418530,"user":{"displayName":"Gaole Lin","userId":"13531080570893436529"},"user_tz":240},"id":"T-9Q6koEVk6Y"},"outputs":[],"source":["# Hyperparameters\n","ORIGINAL_DATASET_DIR = '/content/data_yolo'\n","ACTIVE_DATASET_DIR = '/content/data_active'\n","\n","TRAIN_SUBDIR = 'train'\n","VAL_SUBDIR = 'val'\n","TEST_SUBDIR = 'test'\n","Num_Train = 20093\n","N_INITIAL = int(0.2 * Num_Train)\n","N_PER_PHASE = int(0.01 * Num_Train)\n","NUM_PHASES = 50"]},{"cell_type":"markdown","metadata":{"id":"yuv8_j6DVk6Z"},"source":["# Density-based selection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"mNGjvhsiVk6Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Complete creating train_dir /content/data_active/train\n","Initial Epoch\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.52M/5.52M [00:00\u003c00:00, 306MB/s]"]},{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase0\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=22\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 234/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00\u003c00:00, 187MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1324.1¬±479.0 MB/s, size: 58.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 4018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4018/4018 [00:01\u003c00:00, 3109.58it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0m/content/data_active/train/Tomato leaf curl/leaf curl185_.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1265.8¬±744.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c00:00, 3821.50it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data_active/val.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase0\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.78G      3.298         16        640:   1%|          | 3/252 [00:03\u003c03:34,  1.16it/s]"]},{"name":"stdout","output_type":"stream","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.78G      3.338         16        640:   2%|‚ñè         | 6/252 [00:04\u003c01:25,  2.88it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00\u003c00:00, 124MB/s]\n","        1/1       1.8G      2.267          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:26\u003c00:00,  9.40it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.663      0.962\n","\n","1 epochs completed in 0.010 hours.\n","Optimizer stripped from runs/classify/active-phase0/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase0/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase0/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.663      0.962\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase0\u001b[0m\n","Phase 1: add 200 samples, total sample number: 4218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase0/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase1\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1400.9¬±387.3 MB/s, size: 58.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 4218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4218/4218 [00:01\u003c00:00, 3347.27it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 518.1¬±87.7 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase1\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.43G      1.071         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 264/264 [00:27\u003c00:00,  9.45it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.769      0.989\n","\n","1 epochs completed in 0.011 hours.\n","Optimizer stripped from runs/classify/active-phase1/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase1/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase1/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.769      0.989\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase1\u001b[0m\n","Phase 1 training completed\n","Phase 2: add 200 samples, total sample number: 4418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase1/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase2\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1632.5¬±452.4 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 4418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4418/4418 [00:01\u003c00:00, 3499.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 508.3¬±72.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase2\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.54G     0.8174          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [00:27\u003c00:00, 10.17it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.777      0.994\n","\n","1 epochs completed in 0.010 hours.\n","Optimizer stripped from runs/classify/active-phase2/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase2/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase2/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.777      0.994\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase2\u001b[0m\n","Phase 2 training completed\n","Phase 3: add 200 samples, total sample number: 4618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase2/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase3\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1570.1¬±329.3 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 4618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4618/4618 [00:01\u003c00:00, 3524.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 467.3¬±119.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase3\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.56G     0.7149         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [00:28\u003c00:00, 10.17it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.786      0.994\n","\n","1 epochs completed in 0.011 hours.\n","Optimizer stripped from runs/classify/active-phase3/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase3/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase3/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.786      0.994\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase3\u001b[0m\n","Phase 3 training completed\n","Phase 4: add 200 samples, total sample number: 4818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase3/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase4\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1811.4¬±346.0 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 4818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4818/4818 [00:01\u003c00:00, 3311.15it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 629.6¬±105.7 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase4\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.52G     0.6449          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 302/302 [00:29\u003c00:00, 10.24it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.827      0.997\n","\n","1 epochs completed in 0.011 hours.\n","Optimizer stripped from runs/classify/active-phase4/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase4/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase4/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 4818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.827      0.997\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase4\u001b[0m\n","Phase 4 training completed\n","Phase 5: add 200 samples, total sample number: 5018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase4/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase5\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1873.4¬±372.0 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 5018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5018/5018 [00:01\u003c00:00, 3474.80it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 704.0¬±457.2 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase5\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.78G     0.5989         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 314/314 [00:30\u003c00:00, 10.13it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.831      0.996\n","\n","1 epochs completed in 0.011 hours.\n","Optimizer stripped from runs/classify/active-phase5/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase5/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase5/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       0.83      0.996\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase5\u001b[0m\n","Phase 5 training completed\n","Phase 6: add 200 samples, total sample number: 5218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase5/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase6\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1768.1¬±375.0 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 5218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5218/5218 [00:01\u003c00:00, 3509.86it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 487.1¬±48.2 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase6\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.54G     0.5456          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 327/327 [00:32\u003c00:00, 10.21it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.835      0.998\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from runs/classify/active-phase6/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase6/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase6/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.835      0.998\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase6\u001b[0m\n","Phase 6 training completed\n","Phase 7: add 200 samples, total sample number: 5418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase6/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase7\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1796.4¬±403.3 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 5418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5418/5418 [00:01\u003c00:00, 3389.43it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 465.8¬±62.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase7\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.5229         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 339/339 [00:32\u003c00:00, 10.30it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.835      0.998\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from runs/classify/active-phase7/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase7/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase7/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.835      0.998\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase7\u001b[0m\n","Phase 7 training completed\n","Phase 8: add 200 samples, total sample number: 5618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase7/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase8\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1837.3¬±366.4 MB/s, size: 64.3 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 5618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5618/5618 [00:01\u003c00:00, 3513.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 590.7¬±370.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase8\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.4943          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 352/352 [00:34\u003c00:00, 10.16it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.836      0.999\n","\n","1 epochs completed in 0.012 hours.\n","Optimizer stripped from runs/classify/active-phase8/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase8/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase8/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.837      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase8\u001b[0m\n","Phase 8 training completed\n","Phase 9: add 200 samples, total sample number: 5818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase8/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase9\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1620.0¬±450.6 MB/s, size: 68.1 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 5818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5818/5818 [00:01\u003c00:00, 3535.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 608.0¬±66.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase9\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.56G     0.4698         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 364/364 [00:35\u003c00:00, 10.32it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.835      0.998\n","\n","1 epochs completed in 0.013 hours.\n","Optimizer stripped from runs/classify/active-phase9/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase9/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase9/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 5818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.835      0.998\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase9\u001b[0m\n","Phase 9 training completed\n","Phase 10: add 200 samples, total sample number: 6018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase9/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase10\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1635.4¬±402.9 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 6018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6018/6018 [00:01\u003c00:00, 3483.73it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 486.9¬±44.5 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase10\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.55G     0.4543          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 377/377 [00:35\u003c00:00, 10.59it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.853      0.998\n","\n","1 epochs completed in 0.013 hours.\n","Optimizer stripped from runs/classify/active-phase10/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase10/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase10/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.853      0.998\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase10\u001b[0m\n","Phase 10 training completed\n","Phase 11: add 200 samples, total sample number: 6218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase10/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase11\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1662.3¬±437.4 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 6218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6218/6218 [00:01\u003c00:00, 3484.89it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 963.3¬±594.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase11\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.4433         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 389/389 [00:37\u003c00:00, 10.24it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.859      0.999\n","\n","1 epochs completed in 0.013 hours.\n","Optimizer stripped from runs/classify/active-phase11/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase11/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase11/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.859      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase11\u001b[0m\n","Phase 11 training completed\n","Phase 12: add 200 samples, total sample number: 6418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase11/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase12\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1777.8¬±381.4 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 6418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6418/6418 [00:01\u003c00:00, 3457.48it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 644.7¬±297.6 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase12\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.76G     0.4141          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 402/402 [00:39\u003c00:00, 10.22it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.855      0.999\n","\n","1 epochs completed in 0.014 hours.\n","Optimizer stripped from runs/classify/active-phase12/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase12/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase12/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.853      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase12\u001b[0m\n","Phase 12 training completed\n","Phase 13: add 200 samples, total sample number: 6618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase12/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase13\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1483.3¬±514.0 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 6618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6618/6618 [00:01\u003c00:00, 3474.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 802.6¬±526.8 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase13\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.76G     0.4099         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 414/414 [00:40\u003c00:00, 10.27it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.855          1\n","\n","1 epochs completed in 0.014 hours.\n","Optimizer stripped from runs/classify/active-phase13/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase13/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase13/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.855          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase13\u001b[0m\n","Phase 13 training completed\n","Phase 14: add 200 samples, total sample number: 6818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase13/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase14\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1701.8¬±313.5 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 6818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6818/6818 [00:01\u003c00:00, 3493.39it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 595.3¬±218.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase14\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.55G     0.3799          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 427/427 [00:42\u003c00:00, 10.10it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.869          1\n","\n","1 epochs completed in 0.015 hours.\n","Optimizer stripped from runs/classify/active-phase14/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase14/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase14/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.868          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase14\u001b[0m\n","Phase 14 training completed\n","Phase 15: add 200 samples, total sample number: 7018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase14/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase15\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1731.7¬±345.8 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 7018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7018/7018 [00:02\u003c00:00, 3349.31it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 822.8¬±591.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase15\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.51G     0.3728         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 439/439 [00:41\u003c00:00, 10.47it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.862          1\n","\n","1 epochs completed in 0.015 hours.\n","Optimizer stripped from runs/classify/active-phase15/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase15/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase15/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.861          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase15\u001b[0m\n","Phase 15 training completed\n","Phase 16: add 200 samples, total sample number: 7218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase15/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase16, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase16\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1722.7¬±475.8 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 7218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7218/7218 [00:02\u003c00:00, 3480.26it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 785.7¬±361.2 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase16\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.54G     0.3527          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 452/452 [00:44\u003c00:00, 10.26it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.856      0.998\n","\n","1 epochs completed in 0.015 hours.\n","Optimizer stripped from runs/classify/active-phase16/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase16/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase16/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.857      0.998\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase16\u001b[0m\n","Phase 16 training completed\n","Phase 17: add 200 samples, total sample number: 7418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase16/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase17\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1789.5¬±478.4 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 7418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7418/7418 [00:02\u003c00:00, 3506.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 625.7¬±227.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase17\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1       1.5G      0.362         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 464/464 [00:42\u003c00:00, 10.82it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.859      0.999\n","\n","1 epochs completed in 0.015 hours.\n","Optimizer stripped from runs/classify/active-phase17/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase17/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase17/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.858      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase17\u001b[0m\n","Phase 17 training completed\n","Phase 18: add 200 samples, total sample number: 7618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase17/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase18\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1836.1¬±466.2 MB/s, size: 62.5 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 7618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7618/7618 [00:02\u003c00:00, 3370.26it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 934.6¬±660.9 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase18\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.49G     0.3399          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 477/477 [00:45\u003c00:00, 10.41it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.868          1\n","\n","1 epochs completed in 0.016 hours.\n","Optimizer stripped from runs/classify/active-phase18/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase18/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase18/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       0.87          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase18\u001b[0m\n","Phase 18 training completed\n","Phase 19: add 200 samples, total sample number: 7818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase18/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase19, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase19\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1681.3¬±529.7 MB/s, size: 63.1 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 7818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7818/7818 [00:02\u003c00:00, 3525.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 462.4¬±41.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase19\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.55G     0.3459         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 489/489 [00:47\u003c00:00, 10.40it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.875      0.999\n","\n","1 epochs completed in 0.016 hours.\n","Optimizer stripped from runs/classify/active-phase19/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase19/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase19/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 7818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.875      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase19\u001b[0m\n","Phase 19 training completed\n","Phase 20: add 200 samples, total sample number: 8018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase19/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase20, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase20\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1589.6¬±450.1 MB/s, size: 63.1 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 8018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8018/8018 [00:02\u003c00:00, 3480.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 599.4¬±337.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase20\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.48G     0.3315          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 502/502 [00:48\u003c00:00, 10.29it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.865          1\n","\n","1 epochs completed in 0.017 hours.\n","Optimizer stripped from runs/classify/active-phase20/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase20/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase20/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.865          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase20\u001b[0m\n","Phase 20 training completed\n","Phase 21: add 200 samples, total sample number: 8218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase20/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase21, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase21\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1580.7¬±537.1 MB/s, size: 63.1 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 8218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8218/8218 [00:02\u003c00:00, 3480.50it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 790.0¬±619.8 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase21\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.58G     0.3185         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 514/514 [00:48\u003c00:00, 10.54it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.872          1\n","\n","1 epochs completed in 0.016 hours.\n","Optimizer stripped from runs/classify/active-phase21/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase21/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase21/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.871          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase21\u001b[0m\n","Phase 21 training completed\n","Phase 22: add 200 samples, total sample number: 8418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase21/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase22\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1523.8¬±488.3 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 8418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8418/8418 [00:02\u003c00:00, 3512.02it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 742.4¬±602.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase22\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.74G     0.3067          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 527/527 [00:51\u003c00:00, 10.33it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.859      0.998\n","\n","1 epochs completed in 0.017 hours.\n","Optimizer stripped from runs/classify/active-phase22/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase22/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase22/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.859      0.998\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase22\u001b[0m\n","Phase 22 training completed\n","Phase 23: add 200 samples, total sample number: 8618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase22/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase23, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase23\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1780.0¬±648.7 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 8618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8618/8618 [00:02\u003c00:00, 3499.66it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 608.2¬±102.1 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase23\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.56G     0.3121         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 539/539 [00:51\u003c00:00, 10.42it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.869      0.999\n","\n","1 epochs completed in 0.017 hours.\n","Optimizer stripped from runs/classify/active-phase23/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase23/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase23/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.869      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase23\u001b[0m\n","Phase 23 training completed\n","Phase 24: add 200 samples, total sample number: 8818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase23/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase24, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase24\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1714.4¬±695.2 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 8818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8818/8818 [00:02\u003c00:00, 3461.11it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 587.0¬±83.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase24\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.81G     0.3103          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 552/552 [00:53\u003c00:00, 10.36it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       0.87          1\n","\n","1 epochs completed in 0.018 hours.\n","Optimizer stripped from runs/classify/active-phase24/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase24/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase24/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       0.87          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase24\u001b[0m\n","Phase 24 training completed\n","Phase 25: add 200 samples, total sample number: 9018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase24/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase25, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase25\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1529.2¬±786.1 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 9018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9018/9018 [00:02\u003c00:00, 3438.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 534.0¬±79.3 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase25\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.2979         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 564/564 [00:52\u003c00:00, 10.72it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.869          1\n","\n","1 epochs completed in 0.018 hours.\n","Optimizer stripped from runs/classify/active-phase25/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase25/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase25/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       0.87          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase25\u001b[0m\n","Phase 25 training completed\n","Phase 26: add 200 samples, total sample number: 9218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase25/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase26, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase26\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2015.3¬±845.8 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 9218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9218/9218 [00:02\u003c00:00, 3317.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 606.2¬±269.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase26\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.76G     0.2957          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 577/577 [00:55\u003c00:00, 10.39it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.882          1\n","\n","1 epochs completed in 0.018 hours.\n","Optimizer stripped from runs/classify/active-phase26/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase26/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase26/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.881          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase26\u001b[0m\n","Phase 26 training completed\n","Phase 27: add 200 samples, total sample number: 9418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase26/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase27, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase27\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1772.3¬±674.5 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 9418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9418/9418 [00:02\u003c00:00, 3492.29it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 306.2¬±163.6 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase27\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.49G     0.2943         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 589/589 [00:56\u003c00:00, 10.39it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.872          1\n","\n","1 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/classify/active-phase27/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase27/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase27/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.871          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase27\u001b[0m\n","Phase 27 training completed\n","Phase 28: add 200 samples, total sample number: 9618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase27/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase28, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase28\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1960.8¬±714.1 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 9618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9618/9618 [00:02\u003c00:00, 3408.09it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 571.1¬±206.7 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase28\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.73G     0.2895          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 602/602 [00:57\u003c00:00, 10.40it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.871          1\n","\n","1 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/classify/active-phase28/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase28/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase28/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.871          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase28\u001b[0m\n","Phase 28 training completed\n","Phase 29: add 200 samples, total sample number: 9818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase28/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase29, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase29\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1981.1¬±729.9 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 9818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9818/9818 [00:02\u003c00:00, 3426.25it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 665.9¬±121.5 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase29\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1       1.7G     0.2845         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 614/614 [00:58\u003c00:00, 10.52it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.872      0.999\n","\n","1 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/classify/active-phase29/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase29/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase29/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 9818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.872      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase29\u001b[0m\n","Phase 29 training completed\n","Phase 30: add 200 samples, total sample number: 10018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase29/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase30, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase30\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1918.4¬±880.2 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 10018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10018/10018 [00:02\u003c00:00, 3375.13it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 590.3¬±162.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase30\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.2853          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 627/627 [00:59\u003c00:00, 10.51it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.887      0.999\n","\n","1 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/classify/active-phase30/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase30/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase30/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.887      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase30\u001b[0m\n","Phase 30 training completed\n","Phase 31: add 200 samples, total sample number: 10218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase30/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase31, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase31\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1813.2¬±666.0 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 10218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10218/10218 [00:02\u003c00:00, 3486.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 548.7¬±87.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase31\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.76G     0.2725         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 639/639 [01:00\u003c00:00, 10.52it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.879      0.999\n","\n","1 epochs completed in 0.020 hours.\n","Optimizer stripped from runs/classify/active-phase31/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase31/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase31/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       0.88      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase31\u001b[0m\n","Phase 31 training completed\n","Phase 32: add 200 samples, total sample number: 10418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase31/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase32, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase32\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1631.9¬±644.4 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 10418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10418/10418 [00:02\u003c00:00, 3503.96it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 472.3¬±80.1 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase32\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.56G     0.2616          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [01:02\u003c00:00, 10.40it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.887      0.999\n","\n","1 epochs completed in 0.020 hours.\n","Optimizer stripped from runs/classify/active-phase32/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase32/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase32/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.887      0.999\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase32\u001b[0m\n","Phase 32 training completed\n","Phase 33: add 200 samples, total sample number: 10618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase32/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase33, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase33\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1834.5¬±666.5 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 10618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10618/10618 [00:03\u003c00:00, 3485.29it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 587.6¬±86.9 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase33\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.2605         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 664/664 [01:02\u003c00:00, 10.68it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.886          1\n","\n","1 epochs completed in 0.020 hours.\n","Optimizer stripped from runs/classify/active-phase33/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase33/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase33/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.886          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase33\u001b[0m\n","Phase 33 training completed\n","Phase 34: add 200 samples, total sample number: 10818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase33/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase34, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase34\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1673.2¬±518.3 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 10818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10818/10818 [00:03\u003c00:00, 3465.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 509.3¬±76.2 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase34\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.73G     0.2572          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 677/677 [01:04\u003c00:00, 10.45it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.879          1\n","\n","1 epochs completed in 0.021 hours.\n","Optimizer stripped from runs/classify/active-phase34/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase34/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase34/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.879          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase34\u001b[0m\n","Phase 34 training completed\n","Phase 35: add 200 samples, total sample number: 11018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase34/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase35, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase35\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1802.9¬±738.8 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 11018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11018/11018 [00:03\u003c00:00, 3482.88it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0m/content/data_active/train/Maize leaf beetle/leaf beetle325_.jpg: corrupt JPEG restored and saved\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 472.5¬±75.5 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase35\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.2485         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 689/689 [01:05\u003c00:00, 10.47it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","\n","1 epochs completed in 0.021 hours.\n","Optimizer stripped from runs/classify/active-phase35/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase35/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase35/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase35\u001b[0m\n","Phase 35 training completed\n","Phase 36: add 200 samples, total sample number: 11218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase35/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase36, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase36\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1665.5¬±576.8 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 11218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11218/11218 [00:03\u003c00:00, 3494.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 453.6¬±84.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase36\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.71G     0.2501          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 702/702 [01:07\u003c00:00, 10.45it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.889          1\n","\n","1 epochs completed in 0.022 hours.\n","Optimizer stripped from runs/classify/active-phase36/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase36/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase36/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.889          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase36\u001b[0m\n","Phase 36 training completed\n","Phase 37: add 200 samples, total sample number: 11418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase36/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase37, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase37\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1873.4¬±656.9 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 11418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11418/11418 [00:03\u003c00:00, 3456.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 453.0¬±60.6 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase37\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.54G     0.2414         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [01:07\u003c00:00, 10.56it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.888      0.999\n","\n","1 epochs completed in 0.021 hours.\n","Optimizer stripped from runs/classify/active-phase37/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase37/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase37/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.887          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase37\u001b[0m\n","Phase 37 training completed\n","Phase 38: add 200 samples, total sample number: 11618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase37/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase38, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase38\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1850.0¬±768.4 MB/s, size: 59.0 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 11618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11618/11618 [00:03\u003c00:00, 3327.82it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 441.6¬±66.8 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase38\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.73G     0.2445          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [01:09\u003c00:00, 10.41it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.874          1\n","\n","1 epochs completed in 0.022 hours.\n","Optimizer stripped from runs/classify/active-phase38/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase38/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase38/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.875          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase38\u001b[0m\n","Phase 38 training completed\n","Phase 39: add 200 samples, total sample number: 11818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase38/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase39, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase39\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1602.3¬±627.9 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 11818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11818/11818 [00:03\u003c00:00, 3480.06it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 549.4¬±99.0 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase39\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.56G     0.2302         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 739/739 [01:11\u003c00:00, 10.40it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.884          1\n","\n","1 epochs completed in 0.022 hours.\n","Optimizer stripped from runs/classify/active-phase39/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase39/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase39/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 11818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.885          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase39\u001b[0m\n","Phase 39 training completed\n","Phase 40: add 200 samples, total sample number: 12018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase39/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase40, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase40\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1771.5¬±520.5 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 12018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12018/12018 [00:03\u003c00:00, 3340.19it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 482.3¬±87.5 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase40\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.53G     0.2402          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 752/752 [01:12\u003c00:00, 10.38it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","\n","1 epochs completed in 0.023 hours.\n","Optimizer stripped from runs/classify/active-phase40/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase40/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase40/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase40\u001b[0m\n","Phase 40 training completed\n","Phase 41: add 200 samples, total sample number: 12218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase40/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase41, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase41\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1738.9¬±556.6 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 12218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12218/12218 [00:03\u003c00:00, 3470.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 434.5¬±54.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase41\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.73G     0.2246         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 764/764 [01:13\u003c00:00, 10.42it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","\n","1 epochs completed in 0.023 hours.\n","Optimizer stripped from runs/classify/active-phase41/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase41/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase41/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 11.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.884          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase41\u001b[0m\n","Phase 41 training completed\n","Phase 42: add 200 samples, total sample number: 12418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase41/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase42, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase42\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1641.2¬±628.6 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 12418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12418/12418 [00:03\u003c00:00, 3494.86it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 461.4¬±92.2 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase42\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.72G     0.2371          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 777/777 [01:14\u003c00:00, 10.41it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.881          1\n","\n","1 epochs completed in 0.024 hours.\n","Optimizer stripped from runs/classify/active-phase42/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase42/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase42/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.881          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase42\u001b[0m\n","Phase 42 training completed\n","Phase 43: add 200 samples, total sample number: 12618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase42/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase43, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase43\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1641.0¬±601.1 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 12618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12618/12618 [00:03\u003c00:00, 3482.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 558.8¬±78.6 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase43\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.54G     0.2397         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 789/789 [01:15\u003c00:00, 10.40it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.891          1\n","\n","1 epochs completed in 0.024 hours.\n","Optimizer stripped from runs/classify/active-phase43/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase43/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase43/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.891          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase43\u001b[0m\n","Phase 43 training completed\n","Phase 44: add 200 samples, total sample number: 12818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase43/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase44, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase44\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1759.9¬±570.0 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 12818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12818/12818 [00:03\u003c00:00, 3485.07it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 458.4¬±84.8 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase44\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.71G     0.2211          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 802/802 [01:16\u003c00:00, 10.46it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","\n","1 epochs completed in 0.024 hours.\n","Optimizer stripped from runs/classify/active-phase44/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase44/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase44/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.881          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase44\u001b[0m\n","Phase 44 training completed\n","Phase 45: add 200 samples, total sample number: 13018„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase44/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase45, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase45\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1728.0¬±539.4 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 13018 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13018/13018 [00:03\u003c00:00, 3478.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 465.7¬±87.5 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase45\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.54G     0.2212         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 814/814 [01:18\u003c00:00, 10.43it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.882          1\n","\n","1 epochs completed in 0.024 hours.\n","Optimizer stripped from runs/classify/active-phase45/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase45/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase45/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13018 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:06\u003c00:00, 11.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.883          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase45\u001b[0m\n","Phase 45 training completed\n","Phase 46: add 200 samples, total sample number: 13218„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase45/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase46, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase46\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1608.2¬±673.3 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 13218 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13218/13218 [00:03\u003c00:00, 3479.62it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 459.7¬±46.8 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase46\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.53G     0.2149          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 827/827 [01:19\u003c00:00, 10.37it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.889          1\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/classify/active-phase46/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase46/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase46/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13218 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.888          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase46\u001b[0m\n","Phase 46 training completed\n","Phase 47: add 200 samples, total sample number: 13418„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase46/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase47, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase47\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1797.0¬±583.1 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 13418 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13418/13418 [00:03\u003c00:00, 3496.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 468.2¬±91.4 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase47\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.75G     0.2084         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 839/839 [01:20\u003c00:00, 10.38it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00,  9.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.885          1\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/classify/active-phase47/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase47/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase47/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13418 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00,  9.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.885          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase47\u001b[0m\n","Phase 47 training completed\n","Phase 48: add 200 samples, total sample number: 13618„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase47/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase48, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase48\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1814.0¬±548.5 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 13618 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13618/13618 [00:04\u003c00:00, 3369.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 460.8¬±75.7 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase48\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.53G     0.2175          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 852/852 [01:20\u003c00:00, 10.57it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.887          1\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/classify/active-phase48/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase48/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase48/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13618 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.886          1\n","Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase48\u001b[0m\n","Phase 48 training completed\n","Phase 49: add 200 samples, total sample number: 13818„ÄÇ\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase48/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase49, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase49\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n","YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n","Transferred 236/236 items from pretrained weights\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1828.4¬±527.0 MB/s, size: 57.9 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 13818 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13818/13818 [00:04\u003c00:00, 3389.16it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 534.5¬±117.1 MB/s, size: 66.7 KB)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/active-phase49\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      1.73G     0.2159         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 864/864 [01:22\u003c00:00, 10.44it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:08\u003c00:00,  9.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.889          1\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/classify/active-phase49/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/active-phase49/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/active-phase49/weights/best.pt...\n","Ultralytics 8.3.112 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 13818 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ‚úÖ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ‚úÖ \n"]},{"name":"stderr","output_type":"stream","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:07\u003c00:00, 10.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      0.889          1\n","Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/active-phase49\u001b[0m\n","Phase 49 training completed\n"]}],"source":["from ultralytics import YOLO\n","import random\n","import os\n","\n","# Initialize dataset\n","setup_active_dataset()\n","all_samples = get_all_samples()\n","\n","# Initial sampling and train\n","current_sample_list = stratified_sample(all_samples, N_INITIAL)\n","copy_samples(current_sample_list)\n","\n","print(\"Initial Epoch\")\n","model = YOLO('yolo11n-cls.pt')\n","results = model.train(data=ACTIVE_DATASET_DIR, epochs=1, imgsz=640, name=\"active-phase0\", project=\"runs/classify\")\n","\n","# Compute remaining samples\n","remaining_samples = list(set(all_samples) - set(current_sample_list))\n","\n","# Active Learning (Density-Based)\n","for phase in range(1, NUM_PHASES):\n","    n_to_add = min(N_PER_PHASE, len(remaining_samples))\n","    if n_to_add \u003c= 0:\n","        print(\"No more samples\")\n","        break\n","\n","    # Extract subset features\n","    remaining_indices = [all_samples.index(s) for s in remaining_samples]\n","    subset_features = features.numpy()[remaining_indices]\n","\n","    # Density-based to choose top-k\n","    selected_indices, _ = select_density_samples_from_features(subset_features, k=n_to_add)\n","    new_samples = [remaining_samples[i] for i in selected_indices]\n","\n","    # Update sample list, copy images\n","    copy_samples(new_samples)\n","    current_sample_list.extend(new_samples)\n","    remaining_samples = list(set(remaining_samples) - set(new_samples))\n","\n","    print(f\"Phase {phase}: add {n_to_add} samples, total sample number: {len(current_sample_list)}„ÄÇ\")\n","\n","    # Retrain\n","    model = YOLO(f\"runs/classify/active-phase{phase-1}/weights/last.pt\")\n","    results = model.train(data=ACTIVE_DATASET_DIR, epochs=1, imgsz=640, name=f\"active-phase{phase}\", project=\"runs/classify\")\n","\n","    print(f\"Phase {phase} training completed\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pDF6WZQtVk6Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copied: confusion_matrix.png ‚Üí /content/drive/MyDrive/Colab Notebooks/ASR/results/confusion_matrix_density.png\n","Copied: confusion_matrix_normalized.png ‚Üí /content/drive/MyDrive/Colab Notebooks/ASR/results/confusion_matrix_normalized_density.png\n"]}],"source":["import pandas as pd\n","import csv\n","import os\n","import shutil\n","\n","# Save running log\n","log_path = \"/content/drive/MyDrive/Colab Notebooks/ASR/results/accuracy_log_density.csv\"\n","log_columns = [\"Phase\", \"Epoch\", \"Time\", \"Train Loss\", \"Val Loss\",\n","               \"Top-1 Accuracy\", \"Top-5 Accuracy\", \"LR_pg0\", \"LR_pg1\", \"LR_pg2\"]\n","with open(log_path, \"w\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"Phase\", \"Num_Images\"] + log_columns[1:])\n","\n","# Traverse phase dic\n","for phase in range(NUM_PHASES):\n","    result_csv_path = os.path.join(\"runs\", \"classify\", f\"active-phase{phase}\", \"results.csv\")\n","    if not os.path.exists(result_csv_path):\n","        print(f\"Warning: {result_csv_path} not found.\")\n","        continue\n","\n","    df = pd.read_csv(result_csv_path)\n","    last_row = df.iloc[-1]\n","\n","    # Count num of samples\n","    num_images = N_INITIAL + phase * N_PER_PHASE\n","\n","    with open(log_path, \"a\", newline=\"\") as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\n","            phase,\n","            num_images,\n","            last_row[\"epoch\"],\n","            last_row[\"time\"],\n","            last_row[\"train/loss\"],\n","            last_row[\"val/loss\"],\n","            last_row[\"metrics/accuracy_top1\"],\n","            last_row[\"metrics/accuracy_top5\"],\n","            last_row[\"lr/pg0\"],\n","            last_row[\"lr/pg1\"],\n","            last_row[\"lr/pg2\"]\n","        ])\n","\n","# Save confusion matrix\n","# Last phase\n","last_phase = NUM_PHASES - 1\n","\n","# Path\n","base_path = f\"/content/ASR/Script/runs/classify/active-phase{last_phase}\"\n","confusion_files = [\"confusion_matrix.png\", \"confusion_matrix_normalized.png\"]\n","\n","# Sey Google Drive dictionary\n","drive_target_dir = \"/content/drive/MyDrive/Colab Notebooks/ASR/results\"\n","\n","# Copy\n","for filename in confusion_files:\n","    src = os.path.join(base_path, filename)\n","    dst = os.path.join(drive_target_dir, f\"{filename[:-4]}_density.png\")\n","    if os.path.exists(src):\n","        shutil.copy(src, dst)\n","        print(f\"Copied: {filename} ‚Üí {dst}\")\n","    else:\n","        print(f\"File not found: {src}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Vfpxt9dGfgDb"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["IBtqqZhMVk6X"],"gpuType":"L4","machine_shape":"hm","name":"","version":""},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4280832,"sourceId":7368427,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}