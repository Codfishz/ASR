{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12958,
     "status": "ok",
     "timestamp": 1745188412262,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "PucAEGuTUHXC",
    "outputId": "9ac8595f-bf1a-437d-f368-978f8e8c8d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2166,
     "status": "ok",
     "timestamp": 1745188414430,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "M4lIkMLt25Gd",
    "outputId": "e1b340ca-0722-4bcf-b4bd-c18b1cdfc695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ASR'...\n",
      "warning: redirecting to https://github.com/Codfishz/ASR.git/\n",
      "remote: Enumerating objects: 94, done.\u001b[K\n",
      "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
      "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
      "remote: Total 94 (delta 47), reused 66 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (94/94), 12.27 MiB | 17.21 MiB/s, done.\n",
      "Resolving deltas: 100% (47/47), done.\n"
     ]
    }
   ],
   "source": [
    "# Example: My preferred approach\n",
    "import os\n",
    "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
    "os.environ['GITHUB_TOKEN'] = \"\"\n",
    "\n",
    "GITHUB_USERNAME = \"Codfishz\"\n",
    "REPO_NAME       = \"ASR\"\n",
    "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "!git clone {repo_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1745188414833,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "8aq-iEXz4sFA",
    "outputId": "65583bd3-b70b-4be4-b833-4006b25c41e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: redirecting to https://github.com/Codfishz/ASR.git/\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!cd {REPO_NAME} && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745188414838,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "t-8t_7PV5SuT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('ASR/Script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62178,
     "status": "ok",
     "timestamp": 1745188477026,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "dxy6Mzaf4ckC",
    "outputId": "f870842f-91f4-42bc-8b31-52e0440b0aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==1.7.4.2\n",
      "  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n",
      "Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kaggle\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.7.4.2\n",
      "    Uninstalling kaggle-1.7.4.2:\n",
      "      Successfully uninstalled kaggle-1.7.4.2\n",
      "Successfully installed kaggle-1.7.4.2\n",
      "Dataset URL: https://www.kaggle.com/datasets/nirmalsankalana/crop-pest-and-disease-detection\n",
      "License(s): CC0-1.0\n",
      "✅ Total images found in dataset: 25220\n",
      "Images before filter: 25220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving train: 100%|██████████| 20176/20176 [00:32<00:00, 629.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train split summary:\n",
      "  Total images: 20093\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving val: 100%|██████████| 2522/2522 [00:03<00:00, 648.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val split summary:\n",
      "  Total images: 2514\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving test: 100%|██████████| 2522/2522 [00:03<00:00, 647.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test split summary:\n",
      "  Total images: 2519\n",
      "\n",
      "  Images after filter : 25126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run \"Datapreparation_YOLO.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76260,
     "status": "ok",
     "timestamp": 1745188553289,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "b_ZfVhgCZbg6",
    "outputId": "fe163e2d-f5dc-46c9-d339-4d20a60570dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "Setup complete ✅ (12 CPUs, 53.0 GB RAM, 43.6/235.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install torchinfo\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745188553296,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "-Qg5l7w5vAI4",
    "outputId": "179d4bd4-4a94-47eb-f698-1b9436604cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "print(\"GPU available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745188553313,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "Iz11Fvjg2M3o"
   },
   "outputs": [],
   "source": [
    "def setup_active_dataset():\n",
    "\n",
    "    orig_train_dir = os.path.join(ORIGINAL_DATASET_DIR, TRAIN_SUBDIR)\n",
    "    active_train_dir = os.path.join(ACTIVE_DATASET_DIR, TRAIN_SUBDIR)\n",
    "    os.makedirs(active_train_dir, exist_ok=True)\n",
    "\n",
    "    for cls in os.listdir(orig_train_dir):\n",
    "        cls_path = os.path.join(orig_train_dir, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            os.makedirs(os.path.join(active_train_dir, cls), exist_ok=True)\n",
    "    print(f\"Complete creating train_dir {active_train_dir}\")\n",
    "\n",
    "    orig_val_dir = os.path.join(ORIGINAL_DATASET_DIR, VAL_SUBDIR)\n",
    "    active_val_dir = os.path.join(ACTIVE_DATASET_DIR, VAL_SUBDIR)\n",
    "    if os.path.exists(orig_val_dir):\n",
    "        if os.path.exists(active_val_dir):\n",
    "            shutil.rmtree(active_val_dir)\n",
    "        shutil.copytree(orig_val_dir, active_val_dir)\n",
    "\n",
    "    orig_test_dir = os.path.join(ORIGINAL_DATASET_DIR, TEST_SUBDIR)\n",
    "    active_test_dir = os.path.join(ACTIVE_DATASET_DIR, TEST_SUBDIR)\n",
    "    if os.path.exists(orig_test_dir):\n",
    "        if os.path.exists(active_test_dir):\n",
    "            shutil.rmtree(active_test_dir)\n",
    "        shutil.copytree(orig_test_dir, active_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1745188553375,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "Eg5Ysn_b4Q9D"
   },
   "outputs": [],
   "source": [
    "def get_all_samples():\n",
    "\n",
    "    samples = []\n",
    "    orig_train_dir = os.path.join(ORIGINAL_DATASET_DIR, TRAIN_SUBDIR)\n",
    "    for cls in os.listdir(orig_train_dir):\n",
    "        cls_path = os.path.join(orig_train_dir, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            image_files = [f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]\n",
    "            for f in image_files:\n",
    "                samples.append((cls, f))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745188553379,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "TwCFkNEx4LqF"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "def copy_samples(sample_list):\n",
    "\n",
    "    for cls, file_name in sample_list:\n",
    "        src_path = os.path.join(ORIGINAL_DATASET_DIR, TRAIN_SUBDIR, cls, file_name)\n",
    "        dst_path = os.path.join(ACTIVE_DATASET_DIR, TRAIN_SUBDIR, cls, file_name)\n",
    "        if not os.path.exists(dst_path):\n",
    "            shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745188553381,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "CnqhHfvI5AXe"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def stratified_sample(all_samples, n_initial):\n",
    "\n",
    "    samples_by_class = {}\n",
    "    for cls, filename in all_samples:\n",
    "        samples_by_class.setdefault(cls, []).append((cls, filename))\n",
    "\n",
    "    stratified = []\n",
    "    for cls, samples in samples_by_class.items():\n",
    "        stratified.append(random.choice(samples))\n",
    "    remaining_count = n_initial - len(stratified)\n",
    "    if remaining_count > 0:\n",
    "        remaining_samples = list(set(all_samples) - set(stratified))\n",
    "        additional_samples = random.sample(remaining_samples, remaining_count)\n",
    "        stratified.extend(additional_samples)\n",
    "\n",
    "    return stratified\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745188553385,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "71DA5ol-iN2N"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "ORIGINAL_DATASET_DIR = '/content/data_yolo'\n",
    "ACTIVE_DATASET_DIR = '/content/data_active'\n",
    "\n",
    "TRAIN_SUBDIR = 'train'\n",
    "VAL_SUBDIR = 'val'\n",
    "TEST_SUBDIR = 'test'\n",
    "Num_Train = 20103\n",
    "N_INITIAL = int(0.3 * Num_Train)\n",
    "N_PER_PHASE = int(0.1 * Num_Train)\n",
    "NUM_PHASES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsizXYi0J4SR"
   },
   "source": [
    "# Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468606,
     "status": "ok",
     "timestamp": 1745189021992,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "_SU_i9Lcc0XU",
    "outputId": "9f7a30a5-440b-4668-8ea1-285404fd06a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete creating train_dir /content/data_active/train\n",
      "Initial Epoch\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.52M/5.52M [00:00<00:00, 93.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase0\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6030 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n",
      "YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 106MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1795.6±682.6 MB/s, size: 63.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 6030 images, 0 corrupt: 100%|██████████| 6030/6030 [00:01<00:00, 3477.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data_active/train/Tomato leaf curl/leaf curl185_.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1263.5±825.3 MB/s, size: 66.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|██████████| 2514/2514 [00:00<00:00, 2941.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data_active/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/active-phase0\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.99G      3.249         16        640:   1%|▏         | 5/377 [00:04<02:54,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.99G      3.205         16        640:   4%|▍         | 15/377 [00:04<00:39,  9.27it/s]\n",
      "100%|██████████| 755k/755k [00:00<00:00, 24.9MB/s]\n",
      "        1/1      1.99G      2.017         14        640: 100%|██████████| 377/377 [00:39<00:00,  9.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:08<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.736      0.981\n",
      "\n",
      "1 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/classify/active-phase0/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from runs/classify/active-phase0/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating runs/classify/active-phase0/weights/best.pt...\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 6030 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:07<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.737      0.981\n",
      "Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/active-phase0\u001b[0m\n",
      "Phase 2: add 2010 samples, total sample number: 8040。\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase0/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase1\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8040 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n",
      "YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n",
      "Transferred 236/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1692.7±678.1 MB/s, size: 51.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 8040 images, 0 corrupt: 100%|██████████| 8040/8040 [00:02<00:00, 3481.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/data_active/train/Maize leaf beetle/leaf beetle325_.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 523.5±83.7 MB/s, size: 66.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|██████████| 2514/2514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/active-phase1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.81G     0.8951          8        640: 100%|██████████| 503/503 [00:50<00:00,  9.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:07<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.799      0.995\n",
      "\n",
      "1 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs/classify/active-phase1/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from runs/classify/active-phase1/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating runs/classify/active-phase1/weights/best.pt...\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 8040 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:06<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.8      0.995\n",
      "Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/active-phase1\u001b[0m\n",
      "Phase 2 training completed\n",
      "Phase 3: add 2010 samples, total sample number: 10050。\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase1/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10050 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n",
      "YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n",
      "Transferred 236/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1876.5±661.7 MB/s, size: 54.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 10050 images, 0 corrupt: 100%|██████████| 10050/10050 [00:02<00:00, 3508.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 580.8±175.7 MB/s, size: 66.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|██████████| 2514/2514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/active-phase2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.89G     0.6969          2        640: 100%|██████████| 629/629 [01:00<00:00, 10.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:07<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.82      0.999\n",
      "\n",
      "1 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/classify/active-phase2/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from runs/classify/active-phase2/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating runs/classify/active-phase2/weights/best.pt...\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 10050 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:06<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.82      0.999\n",
      "Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/active-phase2\u001b[0m\n",
      "Phase 3 training completed\n",
      "Phase 4: add 2010 samples, total sample number: 12060。\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase2/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12060 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n",
      "YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n",
      "Transferred 236/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1845.3±507.1 MB/s, size: 61.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 12060 images, 0 corrupt: 100%|██████████| 12060/12060 [00:03<00:00, 3318.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 472.7±46.9 MB/s, size: 66.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|██████████| 2514/2514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/active-phase3\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.86G     0.5991         12        640: 100%|██████████| 754/754 [01:12<00:00, 10.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:08<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833      0.998\n",
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/classify/active-phase3/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from runs/classify/active-phase3/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating runs/classify/active-phase3/weights/best.pt...\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 12060 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:08<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833      0.998\n",
      "Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/active-phase3\u001b[0m\n",
      "Phase 4 training completed\n",
      "Phase 5: add 2010 samples, total sample number: 14070。\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=runs/classify/active-phase3/weights/last.pt, data=/content/data_active, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/classify, name=active-phase4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/active-phase4\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 14070 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    358422  ultralytics.nn.modules.head.Classify         [256, 22]                     \n",
      "YOLO11n-cls summary: 86 layers, 1,559,286 parameters, 1,559,286 gradients, 3.3 GFLOPs\n",
      "Transferred 236/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1975.2±476.9 MB/s, size: 61.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_active/train... 14070 images, 0 corrupt: 100%|██████████| 14070/14070 [00:04<00:00, 3431.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_active/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 756.9±495.2 MB/s, size: 66.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_active/val... 2514 images, 0 corrupt: 100%|██████████| 2514/2514 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/active-phase4\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.87G     0.5383          6        640: 100%|██████████| 880/880 [01:28<00:00,  9.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:07<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.844      0.999\n",
      "\n",
      "1 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/classify/active-phase4/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from runs/classify/active-phase4/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating runs/classify/active-phase4/weights/best.pt...\n",
      "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,554,206 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /content/data_active/train... found 14070 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /content/data_active/val... found 2514 images in 22 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /content/data_active/test... found 2519 images in 22 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:09<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.844      0.999\n",
      "Speed: 0.5ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/active-phase4\u001b[0m\n",
      "Phase 5 training completed\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Initialize dataset\n",
    "setup_active_dataset()\n",
    "all_samples = get_all_samples()\n",
    "\n",
    "# Initial sampling and train\n",
    "current_sample_list = stratified_sample(all_samples, N_INITIAL)\n",
    "copy_samples(current_sample_list)\n",
    "\n",
    "print(\"Initial Epoch\")\n",
    "model = YOLO('yolo11n-cls.pt')\n",
    "results = model.train(data=ACTIVE_DATASET_DIR, epochs=1, imgsz=640, name=\"active-phase0\", project=\"runs/classify\")\n",
    "\n",
    "# Compute remaining samples\n",
    "remaining_samples = list(set(all_samples) - set(current_sample_list))\n",
    "\n",
    "# Active Learning (Random)\n",
    "for phase in range(1, NUM_PHASES):\n",
    "    n_to_add = min(N_PER_PHASE, len(remaining_samples))\n",
    "    if n_to_add <= 0:\n",
    "        print(\"No more samples\")\n",
    "        break\n",
    "\n",
    "    # Add new images\n",
    "    new_samples = random.sample(remaining_samples, n_to_add)\n",
    "    copy_samples(new_samples)\n",
    "\n",
    "    current_sample_list.extend(new_samples)\n",
    "    remaining_samples = list(set(remaining_samples) - set(new_samples))\n",
    "\n",
    "    print(f\"Phase {phase+1}: add {n_to_add} samples, total sample number: {len(current_sample_list)}。\")\n",
    "\n",
    "    # Load last checkpoint and train again\n",
    "    model = YOLO(f\"runs/classify/active-phase{phase-1}/weights/last.pt\")\n",
    "    results = model.train(data=ACTIVE_DATASET_DIR, epochs=1, imgsz=640, name=f\"active-phase{phase}\", project=\"runs/classify\")\n",
    "\n",
    "    print(f\"Phase {phase+1} training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1745189078967,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "Lzi7wscCemHS",
    "outputId": "f7821c69-fe4a-4abc-fa91-9b88af5e7b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Copied: confusion_matrix.png → /content/drive/MyDrive/Colab Notebooks/ASR/results/confusion_matrix_random.png\n",
      "✅ Copied: confusion_matrix_normalized.png → /content/drive/MyDrive/Colab Notebooks/ASR/results/confusion_matrix_normalized_random.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Save running log\n",
    "log_path = \"/content/drive/MyDrive/Colab Notebooks/ASR/results/accuracy_log_random.csv\"\n",
    "log_columns = [\"Phase\", \"Epoch\", \"Time\", \"Train Loss\", \"Val Loss\",\n",
    "               \"Top-1 Accuracy\", \"Top-5 Accuracy\", \"LR_pg0\", \"LR_pg1\", \"LR_pg2\"]\n",
    "with open(log_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Phase\", \"Num_Images\"] + log_columns[1:])\n",
    "\n",
    "# Traverse phase dic\n",
    "for phase in range(NUM_PHASES):\n",
    "    result_csv_path = os.path.join(\"runs\", \"classify\", f\"active-phase{phase}\", \"results.csv\")\n",
    "    if not os.path.exists(result_csv_path):\n",
    "        print(f\"Warning: {result_csv_path} not found.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(result_csv_path)\n",
    "    last_row = df.iloc[-1]\n",
    "\n",
    "    # Count num of samples\n",
    "    num_images = N_INITIAL + phase * N_PER_PHASE\n",
    "\n",
    "    with open(log_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            phase,\n",
    "            num_images,\n",
    "            last_row[\"epoch\"],\n",
    "            last_row[\"time\"],\n",
    "            last_row[\"train/loss\"],\n",
    "            last_row[\"val/loss\"],\n",
    "            last_row[\"metrics/accuracy_top1\"],\n",
    "            last_row[\"metrics/accuracy_top5\"],\n",
    "            last_row[\"lr/pg0\"],\n",
    "            last_row[\"lr/pg1\"],\n",
    "            last_row[\"lr/pg2\"]\n",
    "        ])\n",
    "\n",
    "# Save confusion matrix\n",
    "# Last phase\n",
    "last_phase = NUM_PHASES - 1\n",
    "\n",
    "# Path\n",
    "base_path = f\"/content/ASR/Script/runs/classify/active-phase{last_phase}\"\n",
    "confusion_files = [\"confusion_matrix.png\", \"confusion_matrix_normalized.png\"]\n",
    "\n",
    "# Sey Google Drive dictionary\n",
    "drive_target_dir = \"/content/drive/MyDrive/Colab Notebooks/ASR/results\"\n",
    "\n",
    "# Copy\n",
    "for filename in confusion_files:\n",
    "    src = os.path.join(base_path, filename)\n",
    "    dst = os.path.join(drive_target_dir, f\"{filename[:-4]}_random.png\")\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"Copied: {filename} → {dst}\")\n",
    "    else:\n",
    "        print(f\"File not found: {src}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1745189022731,
     "user": {
      "displayName": "Gaole Lin",
      "userId": "13531080570893436529"
     },
     "user_tz": 240
    },
    "id": "f36kPlizT6uJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
